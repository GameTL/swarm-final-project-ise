\chapter{Odometry}

\section*{Wheel odometry}
{Write regarding wheel odometry here}

\section*{Odometry Validation}
To ensure our odometry is accurate enough for use in SLAM, it must first be validated. Without accurate odometry, the SLAM-generated map may not align correctly with the real-world environment. One of the most effective ways to validate odometry is by using an overhead camera. This camera can track the robotâ€™s movement in real-time and provide a ground-truth odometry reference. We will compare the camera-derived odometry with both wheel odometry and LiDAR-based odometry separately. By analyzing the deviations, we can determine which method is more accurate. If neither source is sufficiently reliable on its own, we will fuse the data from both using an Extended Kalman Filter (EKF) to improve overall accuracy.
\newline

Initially, we considered two approaches for tracking the movement of robots. The first method involved using colored markers placed on the robots and tracking their motion using OpenCV. However, this approach has limitations, as color detection can be unreliable due to lighting variations and camera inaccuracies. The second method we explored was using the ArUco library, which generates unique, square-shaped markers similar to QR codes. These markers can be attached to the robots and tracked using computer vision techniques. This method offers higher accuracy and robustness compared to color-based tracking, as ArUco markers are designed for reliable detection even under varying conditions.